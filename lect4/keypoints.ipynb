{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_142177/4075550855.py:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  return torch.tensor(data, device=device).unsqueeze(1), torch.tensor(labels, device=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), torch.Size([2]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = 28\n",
    "\n",
    "class ShapesDataset(Dataset):\n",
    "    def __init__(self, num_samples, image_size=28):\n",
    "        self.num_samples = num_samples\n",
    "        self.image_size = image_size\n",
    "        self.data, self.labels = self.generate_data(num_samples, image_size)\n",
    "        \n",
    "    def generate_data(self, num_samples, image_size):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for _ in range(num_samples):\n",
    "            image = np.zeros((image_size, image_size), dtype=np.float32)\n",
    "            # Draw a circle\n",
    "            radius = np.random.randint(5, image_size // 4)\n",
    "            center_x = np.random.randint(radius, image_size - radius)\n",
    "            center_y = np.random.randint(radius, image_size - radius)\n",
    "            y, x = np.ogrid[:image_size, :image_size]\n",
    "            mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2\n",
    "            image[mask] = 1.0\n",
    "            data.append(image)\n",
    "            labels.append((center_y / image_size, center_x / image_size))\n",
    "        return torch.tensor(data, device=device).unsqueeze(1), torch.tensor(labels, device=device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Create the dataset and dataloaders\n",
    "train_dataset = ShapesDataset(num_samples=1000, image_size=image_size)\n",
    "test_dataset = ShapesDataset(num_samples=200, image_size=image_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "train_dataset[0][0].shape, train_dataset[0][1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some samples\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    image, (cx, cy) = train_dataset[i]\n",
    "    cx = int(cx * image_size)\n",
    "    cy = int(cy * image_size)\n",
    "    to_show = image.squeeze().cpu().clone()\n",
    "    to_show[cx, cy] = 0.5\n",
    "    axes[i].imshow(to_show, cmap='gray')\n",
    "    # axes[i].set_title(f\"Label: {'Square' if label.item() == 0 else 'Circle'}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 980\n"
     ]
    }
   ],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, \n",
    "                               kernel_size=6, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, \n",
    "                               padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.fc = nn.Linear(12 * 2 * 2, 2)  # Adjust the dimensions accordingly\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.tanh(self.conv1(x)))\n",
    "        x = self.pool(self.tanh(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)  # Flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "torch.manual_seed(31416)\n",
    "\n",
    "print(\"Parameters:\", sum(p.nelement() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.05870351272635162\n",
      "Epoch [3/20], Loss: 0.0012605875817826018\n",
      "Epoch [5/20], Loss: 0.0006751298198651057\n",
      "Epoch [7/20], Loss: 0.00045675043773371724\n",
      "Epoch [9/20], Loss: 0.00034355352334387135\n",
      "Epoch [11/20], Loss: 0.0002905934013688238\n",
      "Epoch [13/20], Loss: 0.00024624758669233415\n",
      "Epoch [15/20], Loss: 0.00022193435761437287\n",
      "Epoch [17/20], Loss: 0.00018383450351393548\n",
      "Epoch [19/20], Loss: 0.00016441953455796466\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    if epoch % (num_epochs // 10) == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"Training complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00017%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_loss = []\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        all_loss.append(loss.item())\n",
    "\n",
    "print(f\"MSE: {np.mean(all_loss):.5f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some samples\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    idx = torch.randint(0, len(test_dataset), (1,))\n",
    "    image, _ = test_dataset[idx.item()]\n",
    "    cx, cy = model(image.unsqueeze(0))[0]\n",
    "    cx = int(cx * image_size)\n",
    "    cy = int(cy * image_size)\n",
    "    to_show = image.squeeze().cpu().clone()\n",
    "    \n",
    "    to_show[cx, cy] = 0.5\n",
    "    axes[i].imshow(to_show, cmap='gray')\n",
    "    # axes[i].set_title(f\"Label: {'Square' if label.item() == 0 else 'Circle'}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More points to detect: square corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), torch.Size([8]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = 28\n",
    "\n",
    "class ShapesDataset(Dataset):\n",
    "    def __init__(self, num_samples, image_size=28):\n",
    "        self.num_samples = num_samples\n",
    "        self.image_size = image_size\n",
    "        self.data, self.labels = self.generate_data(num_samples, image_size)\n",
    "        \n",
    "    def generate_data(self, num_samples, image_size):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for _ in range(num_samples):\n",
    "            image = np.zeros((image_size, image_size), dtype=np.float32)\n",
    "            side = np.random.randint(5, image_size // 2)\n",
    "            top_left_x = np.random.randint(0, image_size - side)\n",
    "            top_left_y = np.random.randint(0, image_size - side)\n",
    "            image[top_left_x:top_left_x+side, top_left_y:top_left_y+side] = 1.0\n",
    "            data.append(image)\n",
    "            points = (\n",
    "                top_left_x, top_left_y, \n",
    "                top_left_x, top_left_y + side - 1,\n",
    "                top_left_x  + side - 1, top_left_y,\n",
    "                top_left_x  + side - 1, top_left_y + side - 1,\n",
    "            )\n",
    "            labels.append([p / image_size for p in points])\n",
    "        return torch.tensor(data, device=device).unsqueeze(1), torch.tensor(labels, device=device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Create the dataset and dataloaders\n",
    "train_dataset = ShapesDataset(num_samples=1000, image_size=image_size)\n",
    "test_dataset = ShapesDataset(num_samples=200, image_size=image_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "train_dataset[0][0].shape, train_dataset[0][1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some samples\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    image, points = train_dataset[i]\n",
    "    to_show = image.squeeze().cpu().clone()\n",
    "    for px, py in points.view(-1, 2):\n",
    "        px = int(px * image_size)\n",
    "        py = int(py * image_size)\n",
    "        to_show[px, py] = 0.5\n",
    "    axes[i].imshow(to_show, cmap='gray')\n",
    "    # axes[i].set_title(f\"Label: {'Square' if label.item() == 0 else 'Circle'}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 1274\n"
     ]
    }
   ],
   "source": [
    "class SquareKPNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SquareKPNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, \n",
    "                               kernel_size=6, padding=1, device=device)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, \n",
    "                               padding=1, device=device)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.fc = nn.Linear(12 * 2 * 2, 8, device=device)  # Adjust the dimensions accordingly\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.tanh(self.conv1(x)))\n",
    "        x = self.pool(self.tanh(self.conv2(x)))\n",
    "        x = x.view(x.shape[0], -1)  # Flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = SquareKPNN()\n",
    "torch.manual_seed(31416)\n",
    "\n",
    "print(\"Parameters:\", sum(p.nelement() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.05871426024939865\n",
      "Epoch [3/20], Loss: 0.005491115861805156\n",
      "Epoch [5/20], Loss: 0.003365690337959677\n",
      "Epoch [7/20], Loss: 0.0023335166997276247\n",
      "Epoch [9/20], Loss: 0.0018097749375738203\n",
      "Epoch [11/20], Loss: 0.0014810307312291115\n",
      "Epoch [13/20], Loss: 0.0012701151278452017\n",
      "Epoch [15/20], Loss: 0.0011152504541678354\n",
      "Epoch [17/20], Loss: 0.0010000202822266146\n",
      "Epoch [19/20], Loss: 0.0009127076054573991\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # update\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    if epoch % (num_epochs // 10) == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"Training complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some samples\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    idx = torch.randint(0, len(test_dataset), (1,))\n",
    "    image, _ = test_dataset[idx.item()]\n",
    "    points = model(image.unsqueeze(0))[0]\n",
    "    to_show = image.squeeze().cpu().clone()\n",
    "    for px, py in points.view(-1, 2):\n",
    "        px = int(px * image_size)\n",
    "        py = int(py * image_size)\n",
    "        to_show[px, py] = 0.5\n",
    "    axes[i].imshow(to_show, cmap='gray')\n",
    "    # axes[i].set_title(f\"Label: {'Square' if label.item() == 0 else 'Circle'}\")\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_teach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
