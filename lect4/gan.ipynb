{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important ideas that allows to generate images:\n",
    "\n",
    "**Idea 1**. We can generate a random image, and using network layers, we can learn to do it properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.randn(100)\n",
    "    x = nn.Linear(100, 28*28)(x)\n",
    "    x = x.view(28, 28)\n",
    "    plt.imshow(x, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use more complex network structures, using CNNs, which we know include local information. For this we will use a ConvTranspose2d layer, which is the 'inverse' of the Conv2d layer.\n",
    "\n",
    "ConvTranspose2d algorithm:\n",
    "- The kernel is moved over the input tensor. \n",
    "- At each position, element-wise product is performed between kernel and corresponding region\n",
    "- Results are summed up to produce the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv = nn.ConvTranspose2d(1, 1, kernel_size=(3, 3), stride=1, padding=0, bias=False)\n",
    "    conv.weight.fill_(1.0)\n",
    "    x = torch.ones(4*4).view(1, 1, 4, 4)*1.0\n",
    "    print(conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stride\n",
    "with torch.no_grad():\n",
    "    conv = nn.ConvTranspose2d(1, 1, kernel_size=(3, 3), stride=2, padding=0, bias=False)\n",
    "    conv.weight.fill_(1.0)\n",
    "    x = torch.ones(4*4).view(1, 1, 4, 4)*1.0\n",
    "    print(conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "with torch.no_grad():\n",
    "    conv = nn.ConvTranspose2d(1, 1, kernel_size=(3, 3), stride=1, padding=1, bias=False)\n",
    "    conv.weight.fill_(1.0)\n",
    "    x = torch.ones(4*4).view(1, 1, 4, 4)*1.0\n",
    "    print(conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even-sized kernel\n",
    "with torch.no_grad():\n",
    "    conv = nn.ConvTranspose2d(1, 1, kernel_size=(2, 2), stride=1, padding=0, bias=False)\n",
    "    conv.weight.fill_(1.0)\n",
    "    x = torch.ones(4*4).view(1, 1, 4, 4)*1.0\n",
    "    print(conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even-sized kernel, stride\n",
    "with torch.no_grad():\n",
    "    conv = nn.ConvTranspose2d(1, 1, kernel_size=(2, 2), stride=2, padding=0, bias=False)\n",
    "    conv.weight.fill_(1.0)\n",
    "    x = torch.ones(4*4).view(1, 1, 4, 4)*1.0\n",
    "    print(conv(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate images using ConvTranspose2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.randn(1, 1, 10*10)\n",
    "    x = x.view(1, 1, 10, 10)\n",
    "    x = nn.ConvTranspose2d(1, 5, kernel_size=7, stride=1, output_padding=0, bias=False)(x)\n",
    "    x = nn.ReLU()(x)\n",
    "    x = nn.ConvTranspose2d(5, 10, kernel_size=7, stride=1, output_padding=0, bias=False)(x)\n",
    "    x = nn.ReLU()(x)\n",
    "    x = nn.ConvTranspose2d(10, 1, kernel_size=7, stride=1, output_padding=0, bias=False)(x)\n",
    "    print(x.shape)\n",
    "    plt.imshow(x.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to train this generative network?:\n",
    "- Using direct backpropagation do not work, because the random nature of the input makes imposible to learn the transformations from real images. \n",
    "- In this way, we could not define a proper a loss.\n",
    "\n",
    "**Idea 2**. We can train a generator indirectly by \"fighting\" a discriminator.\n",
    "\n",
    "<img src=\"images/gan.png\" alt=\"GAN network\" width=\"600\" height=\"400\">\n",
    "\n",
    "Following this idea, the loss of the generator is now defined by its hability to trick the discriminator.\n",
    "- The Generator and Discriminator are trained in parallel in a way that no one gets too good too fast, allowing the other also to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://github.com/SimpleSchwarz/GAN/blob/main/DCGAN_MNIST/DCGAN_MNIST.ipynb\n",
    "\n",
    "DATA_PATH = 'data'\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_CHANNELS = 1\n",
    "NOISE_SIZE = 100\n",
    "G_HIDDEN = 64\n",
    "D_HIDDEN = 64\n",
    "\n",
    "IMAGE_RESIZE = 64\n",
    "EPOCHS = 5\n",
    "REAL_LABEL = 1\n",
    "FAKE_LABEL = 0\n",
    "LEARNING_RATE = 2e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "dataset = datasets.MNIST(root=DATA_PATH, download=True,\n",
    "                     transform=transforms.Compose([\n",
    "                     transforms.Resize(IMAGE_RESIZE),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.5,), (0.5,))\n",
    "                     ]))\n",
    "\n",
    "# Dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils\n",
    "\n",
    "# Plot training images\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input layer\n",
    "            nn.ConvTranspose2d(NOISE_SIZE, G_HIDDEN * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN * 8),\n",
    "            nn.ReLU(True),\n",
    "            # 1st hidden layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN * 8, G_HIDDEN * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN * 4),\n",
    "            nn.ReLU(True),\n",
    "            # 2nd hidden layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN * 4, G_HIDDEN * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN * 2),\n",
    "            nn.ReLU(True),\n",
    "            # 3rd hidden layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN * 2, G_HIDDEN, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN),\n",
    "            nn.ReLU(True),\n",
    "            # output layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN, IMAGE_CHANNELS, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, NOISE_SIZE, 1, 1)\n",
    "print(\"Input\", x.shape)\n",
    "disc = Generator()\n",
    "with torch.no_grad():\n",
    "    for m in disc.main.children():\n",
    "        x = m(x)\n",
    "        if type(m).__name__.startswith('Conv'):\n",
    "            print(f\"[{m}]\")\n",
    "            print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.Conv2d(IMAGE_CHANNELS, D_HIDDEN, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # 2nd layer\n",
    "            nn.Conv2d(D_HIDDEN, D_HIDDEN * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # 3rd layer\n",
    "            nn.Conv2d(D_HIDDEN * 2, D_HIDDEN * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # 4th layer\n",
    "            nn.Conv2d(D_HIDDEN * 4, D_HIDDEN * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(D_HIDDEN * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # output layer\n",
    "            nn.Conv2d(D_HIDDEN * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 1, 64, 64)\n",
    "print(\"Input\", x.shape)\n",
    "disc = Discriminator()\n",
    "with torch.no_grad():\n",
    "    for m in disc.main.children():\n",
    "        x = m(x)\n",
    "        if type(m).__name__.startswith('Conv'):\n",
    "            print(f\"[{m}]\")\n",
    "            print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "# Create the generator\n",
    "model_G = Generator().to(device)\n",
    "model_G.apply(weights_init)\n",
    "\n",
    "# Create the discriminator\n",
    "model_D = Discriminator().to(device)\n",
    "model_D.apply(weights_init)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a classification problem for two classes with a single output we will use BCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.tensor([np.log(4.0), np.log(2.0)])\n",
    "expected = torch.tensor([1.0, 0.0])\n",
    "print(nn.CrossEntropyLoss()(out, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.tensor([4/6])\n",
    "expected = torch.tensor([1.0])\n",
    "print(nn.BCELoss()(out, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(model_D.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(model_G.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def get_gpu_temperature():\n",
    "    try:\n",
    "        result = subprocess.run([\"nvidia-smi\", \"--query-gpu=temperature.gpu\", \"--format=csv,noheader,nounits\"],\n",
    "                                stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "        if result.returncode == 0:\n",
    "            temperature = int(result.stdout.strip())\n",
    "            return temperature\n",
    "        else:\n",
    "            print(\"Error running nvidia-smi:\")\n",
    "            print(result.stderr)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "        return None\n",
    "    \n",
    "get_gpu_temperature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Lists to keep track of progress\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        if get_gpu_temperature() >= 79:\n",
    "            print(\"GPU too hot. Waiting...\")\n",
    "            time.sleep(30)\n",
    "            print(\"- resuming ...\")\n",
    "\n",
    "        # Update the discriminator\n",
    "        model_D.zero_grad()\n",
    "\n",
    "        ### with real data\n",
    "        real_images = data[0].to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        label = torch.full((batch_size,), REAL_LABEL, dtype=torch.float, device=device)\n",
    "        output = model_D(real_images).view(-1)\n",
    "        loss_real = loss_fn(output, label)\n",
    "        loss_real.backward()\n",
    "        conf_D_real = output.mean().item()\n",
    "\n",
    "        ### with fake data\n",
    "        noise = torch.randn(batch_size, NOISE_SIZE, 1, 1, device=device)\n",
    "        fake = model_G(noise)\n",
    "        label.fill_(FAKE_LABEL)\n",
    "        output = model_D(fake.detach()).view(-1)\n",
    "        loss_fake = loss_fn(output, label)\n",
    "        loss_fake.backward()\n",
    "        conf_D_fake = 1 - output.mean().item()\n",
    "        loss_D = loss_real + loss_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Update the generator\n",
    "        model_G.zero_grad()\n",
    "        label.fill_(REAL_LABEL)  \n",
    "        output = model_D(fake).view(-1)\n",
    "        loss_G = loss_fn(output, label)\n",
    "        loss_G.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f'\n",
    "                  % (epoch, EPOCHS, i, len(dataloader),\n",
    "                     loss_D.item(), loss_G.item(), conf_D_real, conf_D_fake))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(loss_G.item())\n",
    "        D_losses.append(loss_D.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.randn(1, 100, 1, 1, device=device)\n",
    "    image = model_G(x)\n",
    "    print(image.shape)\n",
    "    plt.imshow(image[0].squeeze().cpu(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_G.state_dict(), 'models/netG.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Generator()\n",
    "model2.load_state_dict(torch.load('models/netG.pth'))\n",
    "model2 = model2.to(device)\n",
    "model2.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    x = torch.randn(1, 100, 1, 1, device=device)\n",
    "    image = model2(x)\n",
    "    print(image.shape)\n",
    "    plt.imshow(image[0].squeeze().cpu(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_teach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
