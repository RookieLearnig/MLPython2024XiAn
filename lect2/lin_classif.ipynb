{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c423dbf",
   "metadata": {},
   "source": [
    "# Linear Classifiers\n",
    "\n",
    "## Fitting a line to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b980ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba31343a",
   "metadata": {},
   "source": [
    "Supose we are measuring how a mouse weight (X) can be used to predict the mouse size(Y). The values are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28813263",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([0.60316714, 5.13981077, 0.57754654, 3.35880456, 5.28171939,\n",
    "        9.41578636, 2.43742198, 5.99075038, 2.49605785, 6.83781763,\n",
    "        0.16296473, 9.29969598])\n",
    "Y = np.array([15.15613261, 23.89223832, 15.72151754, 16.35859565, 22.06175073,\n",
    "        27.36346235, 20.4802553 , 24.54353801, 21.22924112, 21.77229456,\n",
    "        14.94636364, 30.70479942])\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(X, Y, color='blue', label='Random Points')\n",
    "plt.xlabel('Mouse weight')\n",
    "plt.ylabel('Mouse size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6590cff2",
   "metadata": {},
   "source": [
    "We train to find a good line that fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e885e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line(line, color, ax, values):\n",
    "    min_value = np.min(values)\n",
    "    max_value = np.max(values)\n",
    "    # Generate x-values\n",
    "    x = np.linspace(min_value, max_value, 100)  # range of x-values\n",
    "    y = line(x)\n",
    "    ax.plot(x, y, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e9f52c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(X, Y, color='blue', label='Random Points')\n",
    "line = np.poly1d([1.2, 16])\n",
    "draw_line(line, 'red', ax, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c1d31b",
   "metadata": {},
   "source": [
    "Now it comes the question, is it a good one? Is it the best posible line to fit the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7b3d56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(X, Y, color='blue', label='Random Points')\n",
    "draw_line(np.poly1d([1.2, 16]), 'red', ax, X)\n",
    "draw_line(np.poly1d([1.4, 14]), 'gray', ax, X)\n",
    "draw_line(np.poly1d([0.8, 16]), 'cyan', ax, X)\n",
    "draw_line(np.poly1d([0, 22]), 'green', ax, X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2181b559",
   "metadata": {},
   "source": [
    "We can measure now how well the line fits the data by seen how close is it to the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30643b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "distances = [abs(line(x) - y) for x, y in zip(X, Y)]\n",
    "print(distances)\n",
    "print(sum(distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef00d1ac",
   "metadata": {},
   "source": [
    "Since we want to penalize larger divergences, we square the terms (additionally, the *abs* have some nasty mathematical properties)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e188b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [(line(x) - y)**2 for x, y in zip(X, Y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec187be",
   "metadata": {},
   "source": [
    "if we add all the distances, the result is named **sum of squared residuals (SSR)**, because the **residuals** are the differences between the real and estimated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3df9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c91f92",
   "metadata": {},
   "source": [
    "Now lets create a function for performing the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967bb173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_sq_res(line, X, Y):\n",
    "    return sum((line(x) - y)**2 for x, y in zip(X, Y))\n",
    "\n",
    "sum_sq_res(line, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d2c7d",
   "metadata": {},
   "source": [
    "Lets evaluate the functions we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f7046",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_lines = [\n",
    "    (np.poly1d([1.2, 16]), 'red'), \n",
    "    (np.poly1d([1.4, 14]), 'gray'),\n",
    "    (np.poly1d([0.8, 16]), 'cyan'),\n",
    "    (np.poly1d([0, 22]), 'green'),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(X, Y, color='blue', label='Random Points')\n",
    "for l, color in all_lines:\n",
    "    draw_line(l, color, ax, X)\n",
    "    print(color, sum_sq_res(l, X, Y))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481bc56",
   "metadata": {},
   "source": [
    "As you can see, the better the line fit the data, the smaller value it have on the SSR. \n",
    "\n",
    "Lets try to find the line with the minimal value. This method is called **Least Squares**. We need to find two values:\n",
    "- The curve slope, that controls the angle with respect to the horizontal axis\n",
    "- The curve intercept, that controls the point where the curve cuts the vertical axis.\n",
    "\n",
    "Consider the horizontal line with the average _y_ value. This is not a good one, but since it is based on data, will be our starting point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e7588",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "b = np.average(Y)\n",
    "print(b)\n",
    "line = np.poly1d([0, b])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(X, Y, color='blue', label='Random Points')\n",
    "draw_line(line, 'red', ax, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c245403",
   "metadata": {},
   "source": [
    "Now we explore the influence of the slope in the SSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec90131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for slope in np.arange(-4, 4, 0.1):\n",
    "    line = np.poly1d([slope, b])\n",
    "    ssr = sum_sq_res(line, X, Y)\n",
    "    print(slope, ssr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8855dd0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# using a comprehension\n",
    "points = [(slope, sum_sq_res(np.poly1d([slope, b]), X, Y)) for slope in np.arange(-5, 5, 0.1)]\n",
    "ssrs = np.array(points)\n",
    "plt.plot(ssrs[:, 0],ssrs[:, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98229e3",
   "metadata": {},
   "source": [
    "The ssr function has a derivative that is easy to calculate, allowing us to directly locate the minimum by finding the point where the derivative equals zero.\n",
    "\n",
    "For this example, since we have a computer, we can directly get the slope with lowest ssr value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb27be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_row_index = np.argmin(ssrs[:, 1])\n",
    "min_slope = ssrs[min_row_index, 0]\n",
    "min_slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bcd93a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "b = np.average(Y)\n",
    "print(b)\n",
    "line = np.poly1d([min_slope, b])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(X, Y, color='blue', label='Random Points')\n",
    "draw_line(line, 'red', ax, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c859cb",
   "metadata": {},
   "source": [
    "We can do a similar operation in both parameters simultaneously to find the best line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc392af",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [(slope, c, sum_sq_res(np.poly1d([slope, c]), X, Y)) \n",
    "          for slope in np.arange(-5, 5, 0.1) \n",
    "          for c in np.arange(10, 20, 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1afdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.array(points)\n",
    "points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0e0018",
   "metadata": {},
   "source": [
    "Lets plot the SSR values with respect to slope and c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1966e6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the points in 3D\n",
    "ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=points[:, 2])\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('slope')\n",
    "ax.set_ylabel('c')\n",
    "ax.set_zlabel('SSV')\n",
    "ax.set_title('3D Scatter Plot')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf85226",
   "metadata": {},
   "source": [
    "And get the lowest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b6ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_row_index = np.argmin(points[:,2])\n",
    "min_slope, min_c, ssr = points[min_row_index]\n",
    "min_slope, min_c, ssr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58748877",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "line = np.poly1d([min_slope, min_c])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(X, Y, color='blue', label='Random Points')\n",
    "draw_line(line, 'red', ax, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4527909",
   "metadata": {},
   "source": [
    "Summarizing:\n",
    "- To fit the model to the available data we need to minimize the sum of squared residual from the model and the data\n",
    "- To do this, if we know a good candidate parameter interval, we can explore it. \n",
    "    - We can also analytically calculate the partial derivatives and find the point where it is zero\n",
    "- The point where the SSR is minimal can be used in the model. derivative is zero is the one that minimizes the SSR, so it must be used for the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a72579",
   "metadata": {},
   "source": [
    "## Linear classifiers in Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b292a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/heart.csv')\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Sex\"] = label_encoder.fit_transform(data[\"Sex\"])\n",
    "data[\"ChestPainType\"] = label_encoder.fit_transform(data[\"ChestPainType\"])\n",
    "data[\"RestingECG\"] = label_encoder.fit_transform(data[\"RestingECG\"])\n",
    "data[\"ExerciseAngina\"] = label_encoder.fit_transform(data[\"ExerciseAngina\"])\n",
    "data[\"ST_Slope\"] = label_encoder.fit_transform(data[\"ST_Slope\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c56aaef",
   "metadata": {},
   "source": [
    "### Simple linear regression models\n",
    "Lets try to predict the person Age, based on the other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a96a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Print the coefficients\n",
    "print(\"Coefficients:\", regressor.coef_)\n",
    "print(\"Intercept:\", regressor.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9013f815",
   "metadata": {},
   "source": [
    "And evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf400f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Calculate predicted values\n",
    "y_pred = regressor.predict(X)\n",
    "\n",
    "# Calculate sum of squared errors (SSE)\n",
    "sse = mean_squared_error(y, y_pred) * len(y)\n",
    "\n",
    "# Calculate total sum of squares (SST)\n",
    "sst = np.sum((y - np.mean(y))**2)\n",
    "\n",
    "# Calculate R-squared value\n",
    "r_squared = 1 - (sse / sst)\n",
    "\n",
    "# Calculate p-values using statsmodels\n",
    "X_t = sm.add_constant(X)  # Add constant column for intercept\n",
    "model = sm.OLS(y, X_t)\n",
    "results = model.fit()\n",
    "p_values = results.pvalues\n",
    "\n",
    "# Print results\n",
    "print(\"Sum of Squared Errors (SSE):\", sse)\n",
    "print(\"R-squared:\", r_squared)\n",
    "print(\"P-values:\")\n",
    "for k, p in p_values.items():\n",
    "    print(k, str(round(p, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_teach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
