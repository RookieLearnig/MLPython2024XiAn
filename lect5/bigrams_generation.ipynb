{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da78f5bb",
   "metadata": {},
   "source": [
    "# Generating names using bi-grams\n",
    "We want to generate names in english based on a collection of existing english names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c78f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96afc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store all the names in the file\n",
    "words = open('data/names.txt', 'r').read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8804eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ee4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max / min size of names\n",
    "max(len(w) for w in words), min(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b2d244",
   "metadata": {},
   "source": [
    "# Generating words using probabilities estimated using counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aecd16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bigrams\n",
    "for w in words[:1]:\n",
    "    print('--> ', w)\n",
    "    for ch1, ch2 in zip(w, w[1:]):\n",
    "        print(ch1, ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add special element for starting and ending of words\n",
    "for w in words[:3]:\n",
    "    print('--> ', w)\n",
    "    chs = ['<S>'] + list(w) + ['<E>']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        print(ch1, ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a34cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets learn about the statistics of names, by counting\n",
    "b = {}\n",
    "for w in words[:10]:\n",
    "    chs = ['<S>'] + list(w) + ['<E>']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = ch1, ch2\n",
    "        b[bigram] = b.get(bigram, 0) + 1\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31132299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do it for all the words\n",
    "b = {}\n",
    "for w in words:\n",
    "    chs = ['<S>'] + list(w) + ['<E>']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = ch1, ch2\n",
    "        b[bigram] = b.get(bigram, 0) + 1\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad8592",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets sort by frequency \n",
    "sorted(b.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e021da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the characters\n",
    "all_chars = ['<S>', '<E>'] + sorted(list(set(\"\".join(words))))\n",
    "print(all_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f502de5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mappings between number and encodings\n",
    "itos = {idx: v for idx, v in enumerate(all_chars)}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea037add",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {v: k for k, v in itos.items()}\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3034f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "N = torch.zeros((len(all_chars), len(all_chars)), dtype=torch.int32)\n",
    "for w in words:\n",
    "    chs = ['<S>'] + list(w) + ['<E>']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        N[stoi[ch1], stoi[ch2]] += 1\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b19671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualize it better\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(N)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05cd198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets improve it a little\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "for i in range(len(all_chars)):\n",
    "    for j in range(len(all_chars)):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha='center', va='bottom', color='gray')\n",
    "        plt.text(j, i, N[i,j].item(), ha='center', va='top', color='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14710c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that there is an empty row and an empty column, because start and end markers. \n",
    "# Lets use a single marker, which can be differentiated by the context.\n",
    "\n",
    "all_chars = ['.'] + sorted(list(set(\"\".join(words))))\n",
    "itos = {idx: v for idx, v in enumerate(all_chars)}\n",
    "stoi = {v: k for k, v in itos.items()}\n",
    "\n",
    "N = torch.zeros((len(all_chars), len(all_chars)), dtype=torch.int32)\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        N[stoi[ch1], stoi[ch2]] += 1\n",
    "        \n",
    "# Lets improve it a little\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "for i in range(len(all_chars)):\n",
    "    for j in range(len(all_chars)):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha='center', va='bottom', color='gray')\n",
    "        plt.text(j, i, N[i,j].item(), ha='center', va='top', color='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f56cb7",
   "metadata": {},
   "source": [
    "How can we use this matrix to generate names? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bcd46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts of the first name character\n",
    "N[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms to probabilities\n",
    "p = N[0].float()\n",
    "p = p / p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68a0c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To sample from a distribution we will use torch.multinomial\n",
    "a = torch.tensor([0.7, 0.2, 0.1])\n",
    "sample = torch.multinomial(a, num_samples=100, replacement=True)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(s.item() for s in sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdaa0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now sample from this distribution, using a deterministic generator\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g)\n",
    "ix.item(), itos[ix.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cfbe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets find the second character of the generated word\n",
    "p = N[13].float()\n",
    "p = p / p.sum()\n",
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g)\n",
    "ix.item(), itos[ix.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf17df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and next one ..\n",
    "p = N[9].float()\n",
    "p = p / p.sum()\n",
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g)\n",
    "ix.item(), itos[ix.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets put this into a cycle\n",
    "ix = 0\n",
    "while True:\n",
    "    p = N[ix].float()\n",
    "    p = p / p.sum()\n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g)\n",
    "    ix = ix.item()\n",
    "    if ix == 0:\n",
    "        break\n",
    "    print(itos[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a collection\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for _ in range(20):\n",
    "    ix = 0\n",
    "    result = []\n",
    "    while True:\n",
    "        p = N[ix].float()\n",
    "        p = p / p.sum()\n",
    "        ix = torch.multinomial(p,  num_samples=1, replacement=True, generator=g)\n",
    "        ix = ix.item()\n",
    "        if ix == 0:\n",
    "            break\n",
    "        result.append(itos[ix])\n",
    "    print(\"\".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96443595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One improvement of the code. Calculate the probability matrix instead of the count matrix\n",
    "P = N.float() / N.sum(1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a92d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "P.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da926c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "P[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba18fb9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N[0] / N[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a757d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a collection\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for _ in range(20):\n",
    "    ix = 0\n",
    "    result = []\n",
    "    while True:\n",
    "        p = P[ix].float()\n",
    "        ix = torch.multinomial(p,  num_samples=1, replacement=True, generator=g)\n",
    "        ix = ix.item()\n",
    "        if ix == 0:\n",
    "            break\n",
    "        result.append(itos[ix])\n",
    "    print(\"\".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d27120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the results are not impressive, but it is different than a pure random generator.\n",
    "for _ in range(20):\n",
    "    result = []\n",
    "    while True:\n",
    "        p = torch.ones(len(all_chars))\n",
    "        p = p / p.sum()\n",
    "        ix = torch.multinomial(p,  num_samples=1, replacement=True, generator=g)\n",
    "        ix = ix.item()\n",
    "        if ix == 0:\n",
    "            break\n",
    "        result.append(itos[ix])\n",
    "    print(''.join(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416ec70a",
   "metadata": {},
   "source": [
    "In any case, bigrams do not contains enough information about the names structure in order to generate 'real' ones.\n",
    "- In this example, the probabilities are the parameters learn from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec06ec",
   "metadata": {},
   "source": [
    "## Evaluating the model generated\n",
    "Lets show the probabilities associated to each next character according to the target probability distribution (first three words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33883456",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words[:3]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = ch1, ch2\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        print(f\"{ch1}{ch2}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111bb0be",
   "metadata": {},
   "source": [
    "If all the characters were equaly probable, all the probabilities would be 1/27=0.04\n",
    "\n",
    "You can see that many of these probabilities are above that value, and a few are below.\n",
    "\n",
    "If we have a very good model, we expect the probabilities to be very close to 1, so the correct character will be very probable.\n",
    "\n",
    "How to summarize these probabilities into a single number, so we can evaluate the behavior of the model?\n",
    "\n",
    "We will use the likelihood, which in this case is the product of all the probabilities assigned by the model.\n",
    "- This product will be near to 1 when all the probabilities are closer to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = 1\n",
    "for w in words[:3]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = ch1, ch2\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        likelihood *= prob\n",
    "likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7faeb6f",
   "metadata": {},
   "source": [
    "Since multiplying very small numbers will drop to zero very fast, we will use the logarithm (log-likehood). \n",
    "- Note that the logarithm function is monotonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words[:3]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = ch1, ch2\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        print(f\"{ch1}{ch2}: {prob:.4f} {logprob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023803af",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "for w in words[:3]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = ch1, ch2\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        n += 1\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "log_likelihood, (log_likelihood / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64452b0d",
   "metadata": {},
   "source": [
    "Since we are finding a loss function, we need lower values to be better, so we can multiply the average log-likelihood by -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773078b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll = -log_likelihood\n",
    "nll, nll / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets calculate the average nll in the whole dataset\n",
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = ch1, ch2\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        n += 1\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "nll = -log_likelihood\n",
    "nll / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af713a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can evaluate the nll in any word\n",
    "for w in ['mary', 'joanne', 'balakrishnan', 'fakir', 'keshia', 'gavfed']:\n",
    "    log_likelihood = 0.0\n",
    "    n = 0\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = ch1, ch2\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        n += 1\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "    nll = -log_likelihood\n",
    "    print(w, nll/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866a4ae",
   "metadata": {},
   "source": [
    "The last result is due to the (v,f) bigram never appears in the dataset, so its probability is zero, and the logarithms is infinite.\n",
    "\n",
    "In order to solve this problem, we can add one to all the counts in the counts matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3a9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N + 1).float() / N.sum(1, keepdim=True)\n",
    "\n",
    "# You can evaluate the nll in any word\n",
    "for w in ['mary', 'joanne', 'balakrishnan', 'fakir', 'keshia', 'gavfed']:\n",
    "    log_likelihood = 0.0\n",
    "    n = 0\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = ch1, ch2\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        n += 1\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "    nll = -log_likelihood\n",
    "    print(w, nll/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94912ab7",
   "metadata": {},
   "source": [
    "Resume:\n",
    "- We train a model to generate names based on frequency counting\n",
    "- We estimate probabilities using the counting, solving the zero-counts problems\n",
    "- We develop a way to evaluate the quality of the model using the negative log-likehood\n",
    "- We generate words based on the model. Words are not very good, but they are better than a pure random model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6aa30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_teach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
